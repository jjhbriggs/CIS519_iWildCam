{"cells":[{"cell_type":"markdown","metadata":{"id":"RO_JDWGKBHoC"},"source":["# The code will implement the training pipeline for the CNN regressor mentioned in https://www.nature.com/articles/s41598-021-02387-9"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":856,"status":"ok","timestamp":1682303437221,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"aAuUM7DGNozY","outputId":"d3cbb867-a1e6-45d5-ab26-6fba4e0e9d79"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Seza1fIXCwyx"},"source":["## IMPORT"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":9062,"status":"ok","timestamp":1682303529170,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"iySYyFr4Cyea"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import transforms\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import json\n","import codecs\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682303529171,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"aOKCZIsdGGvw","outputId":"1b2b7a99-a14a-47bb-bd9b-8a0bb1e9eb25"},"outputs":[{"name":"stdout","output_type":"stream","text":["We're using: cpu\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"We're using:\", device)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1682303529171,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"_i5kOzcXhNnA","outputId":"6045f21b-60a1-40ee-b945-6fc5c6336420"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/Shareddrives/CIS519_Spring2023\n"]}],"source":["%cd drive/Shareddrives/CIS519_Spring2023/"]},{"cell_type":"markdown","metadata":{"id":"kdsP0-sz37tp"},"source":["## FASTER DATALOADER (USE IT)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682303529172,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"mfMBOBN5AoRG"},"outputs":[],"source":["class AnimalCountDataset(Dataset):\n","        def __init__(self, image_label, image_data, transform=None):\n","            self.transform = transform\n","            self.label = image_label\n","            self.image = image_data\n","        def __len__(self):\n","          \n","            return len(self.label) \n","            \n","        def __getitem__(self, idx):\n","            \n","            if torch.is_tensor(idx):\n","                idx = idx.tolist()\n","\n","            image = torch.from_numpy(self.image[idx])\n","            image = image.permute(2, 0, 1)\n","            image = image.to(torch.float32)\n","            # Transform the image using self.transform\n","            if self.transform:\n","                image = self.transform(image)\n","            count = torch.tensor(self.label[idx], dtype = torch.float32)\n","            sample = (image, count)\n","            \n","            return sample"]},{"cell_type":"markdown","metadata":{"id":"Wh6ZVrJD6Pjm"},"source":["## preload data"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":55303,"status":"ok","timestamp":1682303584469,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"pTj3TOuB6Wnb"},"outputs":[],"source":["image_save_path = \"/content/drive/Shareddrives/CIS519_Spring2023/image.npy\"\n","label_save_path = \"/content/drive/Shareddrives/CIS519_Spring2023/label.npy\"\n","label = np.load(label_save_path)\n","image = np.load(image_save_path)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":191,"status":"ok","timestamp":1682303584657,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"YkiRqJyMDG1C"},"outputs":[],"source":["transform = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","\n","dataset = AnimalCountDataset(label, image, transform=transform)\n","\n","# define the sizes of the training, testing, and validation datasets\n","train_size = int(0.6 * len(dataset))\n","val_size = int(0.2 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","\n","# use the random_split function to split the dataset into training, validation, and testing datasets\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","\n","# create data loaders for each dataset\n","batch_size = 64\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1682303584657,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"bp-FGXli42qQ","outputId":"b7f860e9-5dcc-4885-d3e2-6f453d4aa747"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5000, 224, 224, 3)\n"]}],"source":["print(image.shape)"]},{"cell_type":"markdown","metadata":{"id":"O0Ux5EHfCYAv"},"source":["## CNN Architecture"]},{"cell_type":"markdown","metadata":{"id":"Otx_hIh4ruZ4"},"source":["### Train pretrained model"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1472,"status":"ok","timestamp":1682303586126,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"SirSpmO7ExEf","outputId":"654fba43-6bf8-44c1-a91b-ef6e3f77e8f4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["import torch.nn as nn\n","import torchvision.models as models\n","\n","# Load a pre-trained ResNet-18 model\n","resnet = models.resnet34(pretrained=True)\n","\n","# Freeze all layers except the last two\n","for param in resnet.parameters():\n","    param.requires_grad = False\n","for param in resnet.fc.parameters():\n","    param.requires_grad = True\n","\n","# Replace the last fully connected layer with a regression layer\n","resnet.fc = nn.Linear(resnet.fc.in_features, 1)\n","resnet = resnet.to(device)"]},{"cell_type":"markdown","metadata":{"id":"bs1_UwEZrzBg"},"source":["### Train the whole model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1682303586364,"user":{"displayName":"John Briggs","userId":"13740578110707342158"},"user_tz":240},"id":"dVoeIQHur3Eq","outputId":"c453c804-624b-43e7-bfe7-0db7c19597a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}],"source":["import torch.nn as nn\n","import torchvision.models as models\n","\n","# Load a pre-trained ResNet-18 model\n","resnet = models.resnet18(pretrained=False)\n","\n","# Replace the last fully connected layer with a regression layer\n","resnet.fc = nn.Linear(resnet.fc.in_features, 1)\n","resnet = resnet.to(device)"]},{"cell_type":"markdown","metadata":{"id":"iNnU3esECi0q"},"source":["## Train, validation, test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"3eI4L8iZBEGy"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1:\n","Training Loss: 1.437\n","Validation Loss: 1.785\n","------------------------------\n","Epoch 2:\n","Training Loss: 1.17\n","Validation Loss: 1.35\n","------------------------------\n","Epoch 3:\n","Training Loss: 1.056\n","Validation Loss: 1.16\n","------------------------------\n","Epoch 4:\n","Training Loss: 0.929\n","Validation Loss: 1.213\n","------------------------------\n","Epoch 5:\n","Training Loss: 0.858\n","Validation Loss: 1.162\n","------------------------------\n"]}],"source":["# Define the loss function and optimizer,\n","criterion = nn.HuberLoss()\n","optimizer = torch.optim.SGD(resnet.parameters(), lr=0.001, momentum= 0.9)\n","\n","# Train the model\n","train_loss, validation_loss = [], []\n","# train_acc, validation_acc = [], []\n","\n","\n","# Note that we have set the number of epochs to be 10. You can choose to increase or decrease the number of epochs.\n","num_epochs = 30 \n","for epoch in range(num_epochs):\n","    \n","    resnet.train()\n","    running_loss = 0.\n","    # running_acc = 0\n","\n","    for i, data in enumerate(train_dataloader):\n","\n","        inputs, labels = data\n","        # 1. Store the inputs and labels in the GPU\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        labels = labels.flatten()\n","        #print(labels)\n","        # 2. Get the model predictions\n","        predictions = resnet(inputs)\n","        predictions = predictions.flatten()\n","        #print(predictions)\n","        # 3. Zero the gradients out\n","        optimizer.zero_grad()\n","\n","        # 4. Get the loss\n","        loss = criterion(predictions, labels)\n","\n","        # 5. Calculate the gradients\n","        loss.backward()\n","\n","        # 6. Update the weights\n","        optimizer.step()\n","            \n","        running_loss += loss.item()\n","        # acc = torch.abs(predictions-labels)/labels\n","        # acc = torch.sum(acc)\n","        # running_acc += acc.item()\n","\n","    # train_acc.append(running_acc/ len(train_dataloader))\n","    train_loss.append(running_loss / len(train_dataloader))\n","            \n","    resnet.eval()\n","    running_loss = 0\n","    # running_acc = 0\n","    \n","    for i, data in enumerate(val_dataloader, 0):\n","\n","        inputs, labels = data\n","        # 1. Store the inputs and labels in the GPU\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        labels = labels.flatten()\n","        \n","        # 2. Get the model predictions\n","        predictions = resnet(inputs)\n","        predictions = predictions.flatten()\n","        \n","        # 3. Get the loss\n","        loss = criterion(predictions, labels)\n","\n","        running_loss += loss.item()\n","        # acc = torch.abs(predictions-labels)/labels\n","        # acc = torch.sum(acc)\n","        # running_acc += acc.item()\n","\n","    # validation_acc.append(running_acc/ len(val_dataloader))\n","    validation_loss.append(running_loss / len(val_dataloader))\n","\n","    print(f\"Epoch {epoch+1}:\")\n","\n","    print(f\"Training Loss:\", round(train_loss[epoch], 3))\n","    print(f\"Validation Loss:\", round(validation_loss[epoch], 3))\n","    \n","    # print(f\"Training Accuracy:\", round(train_acc[epoch], 3))\n","    # print(f\"Validation Accuracy:\", round(validation_acc[epoch], 3))\n","\n","    print(\"------------------------------\")\n","    model_path = \"/content/drive/Shareddrives/CIS519_Spring2023/code/trained_models/resnet34_5000_epoch\"+str(epoch)\n","    torch.save(resnet.state_dict(), model_path)\n","        "]},{"cell_type":"markdown","metadata":{"id":"X3uKLCYhALf-"},"source":["### Loss curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJo_jloGAK59"},"outputs":[],"source":["plt.plot(train_loss,label = \"train\")\n","plt.plot(validation_loss, label = \"validation\")\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"xncZqAmwIWXB"},"source":["## Save the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yw5rBFCdIIVO"},"outputs":[],"source":["PATH = \"/content/drive/Shareddrives/CIS519_Spring2023/code/trained_models/resnet34_5000.pth\"\n","torch.save(resnet.state_dict(), PATH)"]},{"cell_type":"markdown","metadata":{"id":"gw0Ay47IIaLT"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ory3xKBuIUn7"},"outputs":[],"source":["PATH = \"/content/drive/Shareddrives/CIS519_Spring2023/code/trained_models/resnet34_5000.pth\"\n","trained_resnet = models.resnet34(pretrained=False)\n","trained_resnet.fc = nn.Linear(trained_resnet.fc.in_features, 1)\n","state_dict = torch.load(PATH)\n","trained_resnet.load_state_dict(state_dict)\n","trained_resnet.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_eu6ihs2NmfJ"},"outputs":[],"source":["for i in range(100):\n","  test_image, test_label = test_dataset[i]\n","  sq_test_image = test_image.unsqueeze(0)\n","  infer = trained_resnet(sq_test_image)\n","  print(\"GT:\",test_label)\n","  print(\"Prediction:\",infer)"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}